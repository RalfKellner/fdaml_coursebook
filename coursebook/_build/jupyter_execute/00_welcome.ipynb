{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Financial Data Analytics (FDA) refers to the process of analyzing and interpreting various forms of financial data to gain insights, make predictions and support decision-making. This process involves the use of statistical, mathematical, and computational techniques to analyze trends, patterns, and anomalies within financial data sets. FDA is employed across a wide range of applications, including investment strategies, portfolio management, risk management and market analysis. FDA uses data from various sources, such as stock prices, bond markets, derivatives markets, cryptocurrrencies, financial statements, economic indicators, and transaction records, to inform better business decisions.\n",
    "\n",
    "In general, domain specific data analytics always depends on two important knowledge sources: (1) data analytics in general which includes techniques from descriptive and inferential statistics as well as statistical learning, i.e. machine and deep learning. (2) the domain specific knowledge which is crucial for collecting appropriate data, preprocessing and model it the right way and to draw insightful interpretations from the results of your analysis.\n",
    "\n",
    "This is why we aim to unite those two channels in this course. After this course, my goal is that you:\n",
    "\n",
    "* have a fundamental understanding of important assets on financial markets\n",
    "* gathered theoretical background of essential financial theories in this field\n",
    "* understand principles of statistical models and how they can be utilized for empirical financial data analysis\n",
    "* understand principles of machine learing and how it can be used in the financial domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overview:\n",
    "\n",
    "* introduction: assets\n",
    "* definition of random variables: why? - future asset values are random, so to properly analyze them we need  this background\n",
    "    * probabilties\n",
    "    * discrete and continous variables\n",
    "    * multivariate distributions\n",
    "    * simulating data (inverse transform method)\n",
    "* estimation principles for models\n",
    "    * Maximum-Likelihood\n",
    "    * OLS\n",
    "    * General steps -> model with parameters -> data -> adjust parameters to data via optimization minimizing a loss function\n",
    "    * Bias and variance trade off\n",
    "* analyzing distributions of assets by empirical estimation\n",
    "    * expected value with arithmetic mean\n",
    "    * variance (empirical and option variance example), skewness, kurtosis, quantiles (maybe hill estimator as an aggreate estimator for the heavy tail)\n",
    "    * correlation (pearson and spearman)\n",
    "* what to do with these estimates and why?\n",
    "    * forming portfolios because of diversification\n",
    "    * combining portfolios with risk free (bond) investments\n",
    "    * why its not that easy\n",
    "        * parameter uncertainty (example for via shrinkage )\n",
    "        * time horizon - improvement with rolling time estimates?\n",
    "        * different utilities\n",
    "* sophisticated time dependent estimates\n",
    "    * AR, VAR\n",
    "    * GARCH\n",
    "* machine learning\n",
    "    * linear regression models as the 101 model\n",
    "    * parsimony vs. complexity\n",
    "* neural networks\n",
    "    * forward nn: non-linear function approximation -> yield curve example\n",
    "    * stochastic descent\n",
    "    * rnn layer, cnn layer, attention layer\n",
    "    * applications in finance"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}